{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выделение области лица и контуров губ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytube as pt\n",
    "import numpy as np\n",
    "import moviepy as mp\n",
    "import dlib\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('../Models/shape_predictor_68_face_landmarks.dat')\n",
    "WIDTH = cap.get(3)\n",
    "HEIGHT = cap.get(4)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        x1, y1 = face.left(), face.top()\n",
    "        x2, y2 = face.right(), face.bottom()\n",
    "        \n",
    "        \n",
    "        landmarks = predictor(gray, face)\n",
    "        \n",
    "        x_min, y_min, x_max, y_max = WIDTH, HEIGHT, 0, 0 \n",
    "        for i in range(48, 60):\n",
    "            x, y = landmarks.part(i).x, landmarks.part(i).y\n",
    "            cv2.circle(frame, (x, y), 2, (0, 0, 255))\n",
    "        \n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [(1, 2), (4, 6), (2, 6), (6, 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_dlib_pybind11.rectangle'>\n",
      "<class '_dlib_pybind11.rectangle'>\n",
      "<class '_dlib_pybind11.rectangle'>\n",
      "<class '_dlib_pybind11.rectangle'>\n",
      "<class '_dlib_pybind11.rectangle'>\n",
      "<class '_dlib_pybind11.rectangle'>\n",
      "<class '_dlib_pybind11.rectangle'>\n",
      "<class '_dlib_pybind11.rectangle'>\n",
      "<class '_dlib_pybind11.rectangle'>\n",
      "<class '_dlib_pybind11.rectangle'>\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('../Parsing/Audio/Dataset/в/возможно//0.mp4')\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('../Models/shape_predictor_68_face_landmarks.dat')\n",
    "WIDTH = cap.get(3)\n",
    "HEIGHT = cap.get(4)\n",
    "FRAMES = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "detections = 0 # Количество кадров с детектированным лицом\n",
    "x1_avg, x2_avg, y1_avg, y2_avg = 0, 0, 0, 0\n",
    "x1_avg_landmark, x2_avg_landmark = 0, 0\n",
    "y1_avg_landmark, y2_avg_landmark = 0, 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        print(type(face))\n",
    "        detections += 1\n",
    "        \n",
    "        landmarks = predictor(gray, face)\n",
    "        x1, y1 = face.left(), face.top()\n",
    "        x2, y2 = face.right(), face.bottom()\n",
    "        x1_avg += x1\n",
    "        x2_avg += x2\n",
    "        y1_avg += y1\n",
    "        y2_avg += y2\n",
    "        \n",
    "        mouth_landmarks = landmarks.parts()[48:60]\n",
    "        for i, landmark in enumerate(mouth_landmarks):\n",
    "            x, y = landmark.x, landmark.y\n",
    "            if i == 0:\n",
    "                x1_avg_landmark += x\n",
    "                y1_avg_landmark += y\n",
    "            elif i == 6:\n",
    "                x2_avg_landmark += x\n",
    "                y2_avg_landmark += y\n",
    "                \n",
    "            cv2.circle(frame, (x, y), 2, (0, 0, 255))\n",
    "        \n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "        \n",
    "    time.sleep(0.1)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "x1_avg = int(x1_avg / detections)\n",
    "x2_avg = int(x2_avg / detections)\n",
    "y1_avg = int(y1_avg / detections)\n",
    "y2_avg = int(y2_avg / detections)\n",
    "\n",
    "x1_avg_landmark = int(x1_avg_landmark / detections)\n",
    "x2_avg_landmark = int(x2_avg_landmark / detections)\n",
    "y1_avg_landmark = int(y1_avg_landmark / detections)\n",
    "y2_avg_landmark = int(y2_avg_landmark / detections)\n",
    "\n",
    "\n",
    "\n",
    "angle = np.arctan2(y2_avg_landmark - y1_avg_landmark,\n",
    "                  x2_avg_landmark - x1_avg_landmark)\n",
    "angle = 180 * angle / np.pi\n",
    "\n",
    "face = dlib.rectangle(x1_avg, y1_avg, x2_avg, y2_avg)\n",
    "\n",
    "\n",
    "x_min, y_min, x_max, y_max = 200, 300, 0, 0\n",
    "\n",
    "cap = cv2.VideoCapture('../Parsing/Audio/Dataset/в/войти/0.mp4')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    cv2.rectangle(frame, (x1_avg, y1_avg), \n",
    "                  (x2_avg, y2_avg), (0, 255, 255), 2)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    landmarks = predictor(gray, face)\n",
    "    mouth_landmarks = landmarks.parts()[48:60]\n",
    "    for i, landmark in enumerate(mouth_landmarks):\n",
    "        \n",
    "        x, y = landmark.x, landmark.y\n",
    "        x_min = min(x, x_min)\n",
    "        x_max = max(x, x_max)\n",
    "        y_min = min(y, y_min)\n",
    "        y_max = max(y, y_max)\n",
    "        \n",
    "        cv2.circle(frame, (x, y), 2, (0, 0, 255))\n",
    "        \n",
    "    frame = imutils.rotate(frame, angle, \n",
    "                           center=(face.center().x, face.center().y))\n",
    "    img_cropped = frame[face.top() : face.bottom(),\n",
    "                       face.left() : face.right()]\n",
    "    img_cropped = imutils.resize(img_cropped, width=200, height=300)\n",
    "    \n",
    "    cv2.imshow('frame_cropped', img_cropped)    \n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cap = cv2.VideoCapture('../Parsing/Audio/Dataset/в/войти/0.mp4')\n",
    "angle = np.arctan2(x_max - x_min, y_max - y_min)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    rot_frame = imutils.rotate(frame, angle)\n",
    "    cv2.imshow('rotated frame', rot_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "        \n",
    "    time.sleep(0.1)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_max - x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_max - y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.88737489198555"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tan(1.47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arctan2(y_max - y_min, x_max - x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.647970691387034"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "180 * a / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "imutils.rotate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunck:\n",
    "    def __init__(self, video_path, shape_predictor_path, size=(300, 270)):\n",
    "        self.path = video_path\n",
    "        self.size = size\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        self.predictor = dlib.shape_predictor(shape_predictor_path)\n",
    "        self.x1_avg_face, self.x2_avg_face = 0, 0\n",
    "        self.y1_avg_face, self.y2_avg_face = 0, 0\n",
    "        self.x1_avg_landmark, self.x2_avg_landmark = 0, 0\n",
    "        self.y1_avg_landmark, self.y2_avg_landmark = 0, 0\n",
    "        self.angle = 0\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        self.WIDTH = int(cap.get(3))\n",
    "        self.HEIGHT = int(cap.get(4))\n",
    "        self.FRAME_COUNT = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "     \n",
    "    \n",
    "    def prepare(self):\n",
    "        \"\"\"\n",
    "        Метод для подготовки нахождения координат лица, лендмарков\n",
    "        и вращения, чтобы губы были параллельно оси Ox\n",
    "        \"\"\"\n",
    "        \n",
    "        cap = cv2.VideoCapture(self.path)\n",
    "        detections = 0\n",
    "        self.x1_avg_face, self.x2_avg_face = 0, 0\n",
    "        self.y1_avg_face, self.y2_avg_face = 0, 0\n",
    "        self.x1_avg_landmark, self.x2_avg_landmark = 0, 0\n",
    "        self.y1_avg_landmark, self.y2_avg_landmark = 0, 0\n",
    "        self.x_max_landmark, self.y_max_landmark = 0, 0\n",
    "        self.x_min_landmark, self.y_min_landmark = self.WIDTH, self.HEIGHT\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.detector(gray)\n",
    "                   \n",
    "            for face in faces:\n",
    "                detections += 1\n",
    "                self.x1_avg_face += face.left()\n",
    "                self.x2_avg_face += face.right()\n",
    "                self.y1_avg_face += face.top()\n",
    "                self.y2_avg_face += face.bottom()\n",
    "                \n",
    "                landmarks = self.predictor(gray, face)\n",
    "                mouth_landmarks = landmarks.parts()[48:60]\n",
    "                \n",
    "                x_min, x_max, y_min, y_max = self.WIDTH, 0, self.HEIGHT, 0\n",
    "                for i, landmark in enumerate(mouth_landmarks):\n",
    "                    x, y = landmark.x, landmark.y\n",
    "                    if i == 0:\n",
    "                        self.x1_avg_landmark += x\n",
    "                        self.y1_avg_landmark += y\n",
    "                    elif i == 6:\n",
    "                        self.x2_avg_landmark += x\n",
    "                        self.y2_avg_landmark += y\n",
    "                        \n",
    "                    x_min, x_max = min(x, x_min), max(x, x_max)\n",
    "                    y_min, y_max = min(y, y_min), max(y, y_max)\n",
    "                    \n",
    "                self.x_min_landmark = min(self.x_min_landmark, x_min)\n",
    "                self.x_max_landmark = max(self.x_max_landmark, x_max)\n",
    "                self.y_min_landmark = min(self.y_min_landmark, y_min)\n",
    "                self.y_max_landmark = max(self.y_max_landmark, y_max)\n",
    "                        \n",
    "            if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        self.x1_avg_face = int(self.x1_avg_face / detections)\n",
    "        self.x2_avg_face = int(self.x2_avg_face / detections)\n",
    "        self.y1_avg_face = int(self.y1_avg_face / detections)\n",
    "        self.y2_avg_face = int(self.y2_avg_face / detections)\n",
    "        \n",
    "        self.x1_avg_landmark = int(self.x1_avg_landmark / detections)\n",
    "        self.x2_avg_landmark = int(self.x2_avg_landmark / detections)\n",
    "        self.y1_avg_landmark = int(self.y1_avg_landmark / detections)\n",
    "        self.y2_avg_landmark = int(self.y2_avg_landmark / detections)\n",
    "        \n",
    "        a = self.x2_avg_landmark - self.x1_avg_landmark\n",
    "        b = self.y2_avg_landmark - self.y1_avg_landmark\n",
    "        self.angle = 180 * np.arctan2(b, a) / np.pi\n",
    "        \n",
    "        self.face = dlib.rectangle(self.x1_avg_face, self.y1_avg_face,\n",
    "                                  self.x2_avg_face, self.y2_avg_face)\n",
    "        \n",
    "        self.mouth = dlib.rectangle(self.x_min_landmark, self.y_min_landmark, \n",
    "                                   self.x_max_landmark, self.y_max_landmark)\n",
    "        \n",
    "        \n",
    "    def show(self, time_sleep=0):\n",
    "        cap = cv2.VideoCapture(self.path)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            blank = np.zeros((self.HEIGHT, self.WIDTH, 3), dtype=np.uint8)\n",
    "            \n",
    "            \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            landmarks = self.predictor(gray, self.face)\n",
    "            for i, landmark in enumerate(landmarks.parts()[48:60]):\n",
    "                if i != 0:\n",
    "                    x_prev, y_prev = x, y\n",
    "                    cv2.line(blank, (x_prev, y_prev), (x, y), (255, 255, 255), 1)\n",
    "                    \n",
    "                x, y = landmark.x, landmark.y\n",
    "                cv2.circle(frame, (x, y), 2, (0, 0, 255))\n",
    "                \n",
    "                #cv2.circle(blank, (x, y), 1, (255, 255, 255))\n",
    "                \n",
    "            cv2.imshow('blank line', blank)\n",
    "                \n",
    "                \n",
    "            frame = imutils.rotate(frame, self.angle, center=(self.face.center().x,\n",
    "                                                        self.face.center().y))\n",
    "            blank = imutils.rotate(blank, self.angle, center=(self.face.center().x,\n",
    "                                                        self.face.center().y))\n",
    "               \n",
    "            # Crop mouth area\n",
    "            top = int(self.mouth.top() - 0.5 * self.mouth.height())\n",
    "            bottom = int(self.mouth.bottom() + 0.5 * self.mouth.height())\n",
    "            left = int(self.mouth.left() - 0.2 * self.mouth.width())\n",
    "            right = int(self.mouth.right() + 0.2 * self.mouth.width())\n",
    "            frame = frame[top : bottom, left : right]\n",
    "            blank = blank[top : bottom, left : right]\n",
    "            \n",
    "            frame = imutils.resize(frame, width=self.size[0], height=self.size[1])\n",
    "            blank = imutils.resize(blank, width=self.size[0], height=self.size[1])\n",
    "            \n",
    "            cv2.imshow('chunk', frame)\n",
    "            cv2.imshow('blank', blank)\n",
    "            \n",
    "            time.sleep(time_sleep)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "                break\n",
    "                \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def to_file(self, filename):\n",
    "        cap = cv2.VideoCapture(self.path)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(filename, fourcc, 10, (self.size[0],\n",
    "                                                    self.size[1]))\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            blank = np.zeros((self.HEIGHT, self.WIDTH, 3), dtype=np.uint8)\n",
    "             \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            landmarks = self.predictor(gray, self.face)\n",
    "            for i, landmark in enumerate(landmarks.parts()[48:60]):\n",
    "                if i != 0:\n",
    "                    x_prev, y_prev = x, y\n",
    "                    cv2.line(blank, (x_prev, y_prev), (x, y), (255, 255, 255), 1)\n",
    "                    \n",
    "                x, y = landmark.x, landmark.y\n",
    "                cv2.circle(frame, (x, y), 2, (0, 0, 255))\n",
    "                \n",
    "            frame = imutils.rotate(frame, self.angle, center=(self.face.center().x,\n",
    "                                                        self.face.center().y))\n",
    "            blank = imutils.rotate(blank, self.angle, center=(self.face.center().x,\n",
    "                                                        self.face.center().y))\n",
    "               \n",
    "            # Crop mouth area\n",
    "            top = int(self.mouth.top() - 0.5 * self.mouth.height())\n",
    "            bottom = int(self.mouth.bottom() + 0.5 * self.mouth.height())\n",
    "            left = int(self.mouth.left() - 0.2 * self.mouth.width())\n",
    "            right = int(self.mouth.right() + 0.2 * self.mouth.width())\n",
    "            frame = frame[top : bottom, left : right]\n",
    "            blank = blank[top : bottom, left : right]\n",
    "            \n",
    "            frame = imutils.resize(frame, width=self.size[0], height=self.size[1])\n",
    "            blank = imutils.resize(blank, width=self.size[0], height=self.size[1])\n",
    "            blank = cv2.resize(blank, self.size)\n",
    "            print(blank.shape)\n",
    "            \n",
    "            out.write(blank)\n",
    "        \n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunck = Chunck('../Parsing/Audio/Dataset/в/возможно/0.mp4', '../Models/shape_predictor_68_face_landmarks.dat',\n",
    "               size=(30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunck.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunck.show(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n",
      "(30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "chunck.to_file('out.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunck.WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunck.mouth.right()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros((512, 512, 3), dtype=np.uint8)\n",
    "cv2.rectangle(blank, (30, 30), (100, 100), (0, 0, 255), 3)\n",
    "\n",
    "blank = imutils.resize(blank, width=200, height=300)\n",
    "cv2.imshow('img', blank)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunck.HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('out.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width, height = int(cap.get(3)), int(cap.get(4))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('test.avi', fourcc, 10, (width, height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('cam', frame)\n",
    "    out.write(frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('out.avi')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(1)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunk import Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-a84ac85579b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ch = Chunk('../Parsing/Audio/Dataset/з/заданий/0.mp4', \n\u001b[0m\u001b[1;32m      2\u001b[0m           '../Models/shape_predictor_68_face_landmarks.dat')\n",
      "\u001b[0;32m/usr/lib/python3.8/chunk.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mstrflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunkname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunkname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "ch = Chunk('../Parsing/Audio/Dataset/з/заданий/0.mp4', \n",
    "          '../Models/shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-1d5ea9849537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ch' is not defined"
     ]
    }
   ],
   "source": [
    "type(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-c347d1357653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunck\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from .Models.chunck import Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../Modules/')\n",
    "\n",
    "from chunck import Chunck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = Chunck('../Parsing/Audio/Dataset/н/направления/1.mp4',\n",
    "           '../Models/shape_predictor_68_face_landmarks.dat',\n",
    "           size=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.show(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.to_file('test.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
